\chapter{Stand der Forschung}\label{chp:forschungsstand} %3 Seiten Joshua
\glsresetall

Obwohl \gls{acr-KNN} schon seit den frühen 1940er Jahren existieren, führten sie
Langezeit ein Schattendasein in der Informatik. Dies hat sich im letzten
Jahrzehnt entscheidend geändert. Inzwischen sind \gls{acr-KNN} so sehr
verbreitet, dass sie für die Öffentlichkeit häufig synonym zu Künstlicher
Intelligenz im Allgemeinen sind.

Eine Form von \gls{acr-KNN}, die
sicherlich zu dieser Popularität beigetragen haben sind Daten-erzeugende, sog.
\emph{generative \gls{acr-KNN}} \cite{goodfellow2014generative,
kingma2019introduction}. Im Gegensatz zu Regression oder Klassifikation geben
diese Netze keine einfachen skalaren Werte aus, sondern erzeugen komplexe
Datenstrukturen, wie z.\,B. Bilder \cite[S. 100ff.]{goodfellow2016deep}.

\section{Autoencoder}

Eine einfache Form eines generative \gls{acr-KNN} sind
\emph{Autoencoder}. Die grundlegende Idee von Autoentcodern ist es ein Netz zu
erzeugen, dessen Ausgabe schlicht eine Kopie der Eingabe ist \cite[S.
502]{goodfellow2016deep}. Autoencoder setzen also eine Funktion $a(x) \approx x$
um. Dabei kann ein Autoencoder als ein Zusammenschluss von zwei Teilnetzen
verstanden werden: Zum einen den Encoder $f(x) = h$, der aus der Eingabe eine
interne Kodierung $h$ erzeugt (die Aktivierung einer versteckten Schicht), zum
anderen den Decoder $g(h) = r \approx x$, der aus der Kodierung die Eingabe
wiederherstellt. Es wird nun dafür gesorgt, dass der Autoencoder \emph{nicht}
perfekt ist, also die Eingabe nicht eins-zu-eins wiederherstellen kann, sondern
nur eine Näherung ausgibt.

Eine häufige Umsetzung benutzt eine Kodierung $h$,
die eine deutlich geringere Dimensionalität hat als die Eingabe/Ausgabe. Damit
bildet $h$ – bzw. die entsprechende versteckte Schicht – ein Bottleneck, durch das
die Information »fließen« muss \cites[S.503]{goodfellow2016deep}[S. 620f.]{raschka2019}. Da das Netz dadurch keine simple
Identitätsfunktion lernen kann, muss es gewisse Eigenschaften der Eingabe
priorisieren, die es beibehält, um die Daten möglichst gut rekonstruieren zu können.
Davon erhofft man sich, dass das Netz nützliche Eigenschaften und
Repräsentationen der Daten lernt.

Autoencoder können über Standard-Backpropagation trainiert werden. Dabei kommen
Kostenfunktionen zum Einsatz, die die Ungleichheit von Eingabe und Ausgabe
beschreiben, z.\,B. die mittlere quadratische Abweichung \cite[S.
502f.]{goodfellow2016deep}. Autoencoder sind ein zwar einfaches, aber mächtiges
Konzept, das zahlreiche Anwendungen bietet. Traditionell werden sie zur
Dimensionsreduzierung (auf die Dimension der Kodierung) und zum \emph{feature
learning} verwendet \cite[S. 502]{goodfellow2016deep}. Eine andere Anwendung ist
das Entfernen von Rauschen von den eingegebenen Daten.

Was (Standard-)Autoencoder aber nicht leisten, ist das Synthetisieren von neuen
Daten. Allerdings liegt die Idee nahe, Autoencoder, die bereits Daten aus einer
Kodierung wiederherstellen und folglich auch erzeugen können, anzupassen, so dass
komplett neue Daten erzeugt werden können. Dies ist die Idee von Variablen Autoencodern
(\emph{variational autoencoder}). Bei Variablen Autoencodern wird der Encoder
so verändert, dass die gelernte Kodierung auf eine Normalverteilung gezwungen
wird \cite[S. 653]{raschka2019}. Dadurch kann ein neuer Zufallsvektor aus der
Normalverteilung gezogen werden und in den Decoder eingegeben werden, um einen
neuen Datenpunkt zu erstellen.
Neben Variablen Autoencodern existieren noch weitere Ideen, um mit
\gls{acr-KNN} neue Datenpunkte zu erzeugen (z.\,B. \emph{generative
stochastic network} und
\emph{noise-contrastive estimation} \cite[S. 2]{goodfellow2014generative}).

\section{Generative Adversarial Networks}\label{GANs}

Eine weitere wichtige Architektur, die ebenfalls von Autoencodern inspiriert ist,
sind \emph{\gls{acr-GAN}}. \gls{acr-GAN}s, ursprünglich \citeyear{goodfellow2014generative} von
\citeauthor{goodfellow2014generative} in ihrem Paper
\citetitle{goodfellow2014generative} eingeführt, wurden als der wichtigste Durchbruch im
\emph{Deep Learning} bezeichnet \cite[S. 619]{raschka2019}.

Ähnlich wie Variable Autoencoder sind \gls{acr-GAN}s in der Lage aus einem Zufallsvektor
als Eingabe einen sinnvollen Datenpunkt der Zieldomäne zu erzeugen \cite[S.
2]{goodfellow2014generative}. Anknüpfend an den Aufbau von Autoencodern bestehen
\gls{acr-GAN}s aus zwei Teilnetzen. Der \emph{Generator} $G$ entspricht dem
Decoder und soll lernen aus einem Zufallsvektor $z$ einen Datenpunkt zu
erstellen \cites[S. 3]{goodfellow2014generative}[S. 623]{raschka2019}. Der
\emph{Discriminator} $D$ erzeugt zwar nicht den Zufallsvektor,
erhält allerdings wie der Encoder als Eingabe ein (synthetisiertes oder reales)
Datum. Die Ausgabe des Discriminator ist ein Skalar, der die
Wahrscheinlichkeit beschreibt 
mit der es sich dabei um einen realen Datenpunkt (im Gegensatz zu einem vom
Generator erzeugten) handelt \cite[S. 1,3]{goodfellow2014generative}.

Das Training von \gls{acr-GAN}s wird häufig als ein Spiel bzw. Wettkampf
zwischen Generator und Discriminator beschrieben.
Der Generator versucht immer realistischere Datenpunkte
zu erstellen, während der Discriminator versucht immer zuverlässiger
synthetisierte Daten zu erkennen. Damit können im Training beide Netze jeweils
die Ausgabe des anderen zum Training verwenden \cite[S. 625]{raschka2019}.
Zwischen diesen beiden Optimierungsschritten (dem des Generators und dem des
Discriminators) wird im Training abgewechselt, wobei immer ein Netz trainiert
wird und eines konstant gehalten wird \cite[S. 626]{raschka2019}. \Citeauthor{goodfellow2014generative}
trainieren dabei den Discriminator häufiger als den Generator \cite[S.
3]{goodfellow2014generative}.

Die grundlegende Idee von \gls{acr-GAN}s wurde inzwischen für zahlreiche
Anwendungen adaptiert. Diese reichen vom einfachen Generieren von Bildern
\cite{goodfellow2014generative, arjovsky2017wasserstein,
gulrajani2017improved,kurach2018gan, miyato2018spectral} über das »Übersetzen«
von Bildern in einen anderen Stil
\cite{pang2021image,isola2017image,zhu2017unpaired,
liu2019few,saito2020coco,anokhin2020high} und das Erzeugen von
\emph{super-resolution} Bildern, d.\,h. das Verbessern der Auflösung von Bildern
\cite{pang2021image,anokhin2020high,ledig2017photo}, bis hin zu
\emph{Inpainting}, d.\,h. dem »Auffüllen« von fehlenden Teilen eines Bildes
\cite{pang2021image,isola2017image, demir2018patch}.

Trotz dieser zahlreichen Anwendungen, sind \gls{acr-GAN}s sehr schwierig zu
trainieren \cite[S. 1]{kurach2018gan}. Für jede Anwendung muss viel Aufwand in
\emph{Hyperparameter-Tuning}, die Anpassung der neuronalen Architektur und
zahlreiche andere »Tricks« \cite[vgl.][]{kurach2018gan} gesteckt werden. Dies
liegt daran, dass das Trainieren von \gls{acr-GAN}s einer
Minimax-Aufgabe auf einer Vielzahl von Parametern entspricht, die nur sehr
schwer zu lösen ist \cite[S. 1]{kurach2018gan}. In der Praxis führt dies häufig
zu Problemen, wie dem \emph{Mode Collapse}, d.\,h. der Generator lernt den
Eingabevektor zu ignorieren und gibt nur noch ein Datum \cite[S.
4]{pang2021image} oder den von anderen \gls{acr-KNN} bekannten verschwindenden
Gradienten \cite[S. 6]{arjovsky2017towards}. Auch ist es oft schwierig
Konvergenz zu erreichen \cite[S. 4]{pang2021image}.

Um diese Probleme zu beheben, gibt es eine große Variation an vorgeschlagenen
Kostenfunktionen (z.\,B. Anpassungen mit der Wasserstein-Metrik
\cite{arjovsky2017wasserstein} oder der Methode der kleinsten Quadrate \cite[S.
2]{kurach2018gan}), Regularisierungen und Normalisierungen (z.\,B. des
Gradienten oder des ganzen Discriminators \cite[S. 2f.]{kurach2018gan}) und 
Neuronalen Architekturen (z.\,B. die DCGAN \cite{radford2015unsupervised},
SNDCGAN \cite{miyato2018spectral} und ResNet \cite{zhu2017unpaired}
Architekturen) \cite[vgl.][S. 1,3]{kurach2018gan}.

\section{GANs zur Bildmanipulation}

Wie bereits in den Anwendungen oben erwähnt, können GANs nicht nur zum Erstellen
von Datenpunkten, wie z.\,B. Bildern, verwendet werden, sondern auch zu deren
Manipulation (vor allem von Bildern). Dies wird als \emph{\gls{acr-I2I}}
bezeichnet. Das Ziel ist es hierbei ein Bild (d.\,h. den Stil) von einer Domäne
$A$ in eine Domäne $B$ umzuwandeln, wobei der Inhalt des Bildes erhalten bleibt
\cite[S. 1]{pang2021image}. Dabei bezeichnet der »Stil«, der verändert wird,
nicht nur einen Bildstil im engeren Sinne, sondern es können z.\,B. auch Bilder
von Hunden in Bilder von Katzen umgewandelt werden \cite{liu2019few}.
Die Anwendungsmöglichkeiten sind ebenso vielfältig wie für die »normalen«
\gls{acr-GAN}s \cite[vgl.][S. 1]{pang2021image}.

Der Unterschied zu den »normalen« \gls{acr-GAN}s ist nun, dass der Generator
nicht (nur) einen Zufallsvektor als Eingabe erhält, sondern das umzuwandelnde
Bild \cite[S. 1]{pang2021image}. Der Discriminator wird ebenfalls angepasst, z.\,B. erhält er als
zusätzliche Eingabe ebenfalls das ursprüngliche Bild um die Erhaltung des
Inhalts bewerten zu können \cite{isola2017image}.

Bei \gls{acr-I2I} \gls{acr-GAN}s kann man zwischen Netzen unterscheiden, die
Bilder genau zwischen zwei Domänen umwandeln \cite{isola2017image,
zhu2017unpaired, ledig2017photo, demir2018patch} und solchen, die eine Vielzahl von
Domänen unterstützen
\cite{liu2019few,huang2017arbitrary,saito2020coco,anokhin2020high}. Dabei
verwenden die Varianten für mehrere Domänen nicht einfach mehrere Netze, sondern
auch ein einzelnes
Netz. Dieses erhält neben dem umzuwandelnden Bild auch ein oder mehrere Bilder
als Eingabe, die den Ziel-Stil anzeigen \cites[S.
11]{pang2021image}{liu2019few}.
Daneben kann man zwischen Überwachten \cite{isola2017image,ledig2017photo,demir2018patch} und Unüberwachten
\cite{liu2019few,zhu2017unpaired,huang2017arbitrary,saito2020coco,anokhin2020high,}
Varianten unterscheiden\footnote{Teilüberwachte (\emph{semi-supervised})
Varianten existieren ebenfalls \cite[S. 5]{pang2021image}.}  \cite[vgl.][S. 5,
11]{pang2021image}.
Dabei benötigen
überwachte Varianten Bildpaare, die bereits vom Inhalt übereinstimmen, aber die
gewünschten verschiedenen Stile aufweisen. (Bspw. ein Bild von einer Stadt, das
von der exakt gleichen Stelle einmal tagsüber und einmal nachts aufgenommen
wurde.) Da solche gepaarten Daten in der Praxis selten zur Verfügung stehen,
sind unüberwachte Varianten mächtiger. Für diese ist es ausreichend, zwei Mengen
von Beispielen für die beiden Domänen zu haben, die aber nicht die gleichen
Inhalte haben müssen.
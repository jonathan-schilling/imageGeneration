\chapter{Manipulieren von Bildern}\label{chp:bildmanipulation} %10 Seiten
\glsresetall

 \section{Modelle} % Dani
 
\subsection{CycleGAN}% Dani
\label{sub:cyclegan}
 
 \subsection{FUNIT}% Dani
 
 \section{Implementierung} % Tim nach Implementierung Generieren
 Dieser Abschnitt beschreibt die Implementierung eines CycleGAN. mit Tensorflow und Keras. Da dieses GAN deutlich größer als das \gls{acr-SNDCGAN} ist, konnte es, aufgrund der beschränkten Computerressourcen, nur einmal trainiert werden. Alle Trainingsparameter wurden vorher festgelegt, wobei die Erfahrung aus \cref{sec:gen_impl} 
 
 \subsection{Umsetzung in Tensorflow/Keras}
 Wie auch für das \gls{acr-SNDCGAN} wurde ein \enquote{Sequential model} von Keras~\cite{keras:SequentialModel} verwendet um die einzelnen Schichten abzubilden. Da es nicht alle benötigten Netzschichten in Keras  implementiert sind mussten zudem für die ResBlock und ReflectionPadding2D Schichten, siehe \cref{sub:cyclegan}, sowie für Tanh,  eigene Klassen geschrieben werden, welche von einer abstrakten Keras Schicht erben. 
 
 Das Training des CycleGAN wurde ähnlich wie das \gls{acr-SNDCGAN} in \cref{sec:gen_impl} implementiert. Ebenfalls wurde es durch Checkpoints ermöglicht das Netz jederzeit anzuhalten und später weiter zu trainieren. Adam \cite{tf:adam} wurde als Optimizer, und GradientTapes \cite{tf:gradientape} zur Berechnung der Gradienten, verwendet.
 
Die Optimizer sind identisch parametrisiert und wurden wie in der Implementierung von \cite{brownlee_how_2019-1} auf eine Lernrate von 2e-4 und beta1 auf 0.5 gesetzt. 

Da das CycleGAN aus vier mehrschichtigen Netzen besteht, welche zusammen trainiert werden ist es sehr speicherintensiv zu trainieren. Nur dadurch, dass einzelne Trainingsschritte in eine Funktion mit dem \enquote{tf.function} decorater \cite{noauthor_tffunction_nodate}, ausgelagert sind kann die stärkste dem Projekt zur Verfügung stehende Grafikkarte genug speicher bieten, um das Training mit einer geringen Batchgröße durchzuführen. 


 \section{Evaluierung} % TODO Tim und Joshua

 \paragraph{SIFID} Als Metrik für die Evaluierung der Ergebnisse der
 Bildmanipulation wird die \gls{acr-SIFID} verwendet, die von
 \citeauthor{shaham2019singan} in ihrem Paper \citetitle{shaham2019singan}
 \cite{shaham2019singan} eingeführt wurde. Dies ist eine Erweiterung der bereits
 für die Bildgenerierung verwendeten \gls{acr-FID} \cite{heusel2017gans} (vgl.
 \cref{evalGen} % TODO: Ist die da beschrieben?
 ). Anstatt die Differenz zwischen der Merkmalsverteilung für eine
 Gruppe von generierten und eine Gruppe von originalen Bildern zu messen (so wie
 die \gls{acr-FID}), misst die \gls{acr-SIFID} die Differenz zwischen einem
 Eingabebild in das I2I GAN und dem erzeugen Ausgabebild
 \cite[S. 4575]{shaham2019singan}. Wie die \gls{acr-FID} vergleicht die
 \gls{acr-SIFID} dabei die Aktivierung einer versteckten Schicht des
 \emph{Inception Networks} \cite{szegedy2015going}.
 %TODO: Ist das im Bilderzeugungs-Evaluierungskapitel so vorhanden?
 Anstatt allerdings die
 Aktivierung nach der letzten Pooling-Schicht zu verwenden, nutzt die
 \gls{acr-SIFID} die »tiefen« Eigenschaften, die in der Aktivierung der
 Convolution-Schicht vor der zweiten Pooling-Schicht zu finden sind \cite[S.
 4575]{shaham2019singan}. Wie für die \gls{acr-FID} sind niedrige Werte besser,
 sie bedeuten, dass der Unterschied zwischen den beiden Bildern geringer ist
 \cite[S. 5]{pang2021image}.
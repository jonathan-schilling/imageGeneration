
@misc{brada2022,
  title = {{{PyQt Image Annotation Tool}}},
  author = {Brada, Robert},
  year = {2022},
  month = feb,
  url = {https://github.com/robertbrada/PyQt-image-annotation-tool},
  urldate = {2022-03-08},
  abstract = {Tool for assigning labels to images from a given folder.}
}

@misc{brownlee2019,
  title = {Tips for {{Training Stable Generative Adversarial Networks}}},
  author = {Brownlee, Jason},
  year = {2019},
  month = jun,
  journal = {Machine Learning Mastery},
  url = {https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/},
  urldate = {2022-03-10},
  abstract = {The Empirical Heuristics, Tips, and Tricks That You Need to Know to Train Stable Generative Adversarial Networks (GANs). Generative Adversarial [\ldots ]},
  language = {en-US},
  file = {/Users/jonathan/Zotero/storage/RQUTZK9I/how-to-train-stable-generative-adversarial-networks.html}
}

@misc{keras:SequentialModel,
  title = {Keras documentation: {{The Sequential}} model},
  shorttitle = {Keras documentation},
  author = {Team Keras},
  url = {https://keras.io/guides/sequential_model/},
  urldate = {2022-03-10},
  abstract = {Keras documentation},
  language = {en},
  file = {/Users/jonathan/Zotero/storage/Q7IJHQ2P/sequential_model.html}
}

@article{kingma2014,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2014},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.1412.6980},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{KYD:OIv4,
  title = {Know {{Your Data}}: {{OpenImagesV4}}},
  author = {team Google, The PAIR},
  url = {https://knowyourdata-tfds.withgoogle.com/#tab=STATS&dataset=open_images_v4},
  urldate = {2022-03-07},
  file = {/Users/jonathan/Zotero/storage/ICUWDKNP/knowyourdata-tfds.withgoogle.com.html}
}

@misc{OIv4:Download,
  title = {Open {{Images V6}} - {{Download}}},
  url = {https://storage.googleapis.com/openimages/web/download.html#download_manually},
  urldate = {2022-03-07},
  file = {/Users/jonathan/Zotero/storage/ERGLXKNG/download.html}
}

@article{OpenImages,
  title = {The {{Open Images Dataset V4}}: {{Unified}} image classification, object detection, and visual relationship detection at scale},
  author = {Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and {Pont-Tuset}, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Duerig, Tom and Ferrari, Vittorio},
  year = {2018},
  journal = {arXiv:1811.00982},
  eprint = {1811.00982},
  eprinttype = {arxiv},
  archiveprefix = {arXiv}
}

@article{OpenImages2,
  title = {{{OpenImages}}: {{A}} public dataset for large-scale multi-label and multi-class image classification.},
  author = {Krasin, Ivan and Duerig, Tom and Alldrin, Neil and Ferrari, Vittorio and {Abu-El-Haija}, Sami and Kuznetsova, Alina and Rom, Hassan and Uijlings, Jasper and Popov, Stefan and Kamali, Shahab and Malloci, Matteo and {Pont-Tuset}, Jordi and Veit, Andreas and Belongie, Serge and Gomes, Victor and Gupta, Abhinav and Sun, Chen and Chechik, Gal and Cai, David and Feng, Zheyun and Narayanan, Dhyanesh and Murphy, Kevin},
  year = {2017},
  journal = {Dataset available from https://storage.googleapis.com/openimages/web/index.html}
}

@inproceedings{parkhi12a,
  title = {Cats and dogs},
  booktitle = {{{IEEE}} conference on computer vision and pattern recognition},
  author = {Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C. V.},
  year = {2012}
}

@misc{Pets:Download,
  title = {The {{Oxford}}-{{IIIT Pet Dataset}}},
  author = {Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C. V.},
  url = {https://www.robots.ox.ac.uk/~vgg/data/pets/},
  urldate = {2022-03-08},
  file = {/Users/jonathan/Zotero/storage/KGKQGKAT/pets.html}
}

@book{raschka2019,
  title = {Python machine learning: machine learning and deep learning with {{Python}}, scikit-learn, and {{TensorFlow}} 2},
  shorttitle = {Python machine learning},
  author = {Raschka, Sebastian and Mirjalili, Vahid},
  year = {2019},
  series = {Expert insight},
  edition = {Third edition},
  publisher = {{Packt}},
  address = {{Birmingham Mumbai}},
  isbn = {978-1-78995-575-0},
  language = {eng}
}

@misc{tf:adam,
  title = {tf.keras.optimizers.{{Adam}} | {{TensorFlow Core}} v2.8.0},
  author = {TensorFlow},
  journal = {TensorFlow},
  url = {https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam},
  urldate = {2022-03-10},
  abstract = {Optimizer that implements the Adam algorithm.},
  language = {en},
  file = {/Users/jonathan/Zotero/storage/GBLYS4QF/Adam.html}
}

@misc{tf:autodiff,
  title = {Introduction to gradients and automatic differentiation | {{TensorFlow Core}}},
  author = {TensorFlow},
  journal = {TensorFlow},
  url = {https://www.tensorflow.org/guide/autodiff},
  urldate = {2022-03-10},
  language = {en},
  file = {/Users/jonathan/Zotero/storage/XSSFXH54/autodiff.html}
}

@misc{tf:gradientape,
  title = {tf.{{GradientTape}} | {{TensorFlow Core}} v2.8.0},
  author = {TensorFlow},
  journal = {TensorFlow},
  url = {https://www.tensorflow.org/api_docs/python/tf/GradientTape},
  urldate = {2022-03-10},
  abstract = {Record operations for automatic differentiation.},
  language = {en},
  file = {/Users/jonathan/Zotero/storage/8EVKD5TZ/GradientTape.html}
}


